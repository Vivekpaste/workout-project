{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python mediapipe==0.10.7\n",
    "%pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing=mp.solutions.drawing_utils\n",
    "mp_pose=mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing mediapipe and camera feed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2. VideoCapture (0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap. read ()\n",
    "        # Recolor Feed\n",
    "        image = cv2. cvtColor (image, cv2. COLOR_BGR2RGB)\n",
    "        image. flags.writeable = False\n",
    "        \n",
    "        results = pose. process (image)\n",
    "        \n",
    "        image.flags. writeable = True\n",
    "        image = cv2. cvtColor (image, cv2. COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose. POSE_CONNECTIONS\n",
    "                                    , mp_drawing. DrawingSpec(color=(0,255,0), thickness=2, circle_radius=4), \n",
    "                                    mp_drawing. DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)\n",
    "                                \n",
    "        )\n",
    "        cv2. imshow( 'Raw Webcam Feed', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a video to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2. VideoCapture (0)\n",
    "height = cap.get (cv2. CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap. get (cv2.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get (cv2. CAP_PROP_FPS)\n",
    "videoWriter = cv2. VideoWriter('press.avi', cv2.VideoWriter_fourcc('P','I', 'M','1'), fps, (int(width), int(height)))\n",
    "while cap. isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        cv2. imshow( 'Press', frame)\n",
    "        videoWriter.write (frame)\n",
    "    except Exception as e:\n",
    "        break\n",
    "    if cv2.waitKey (1) & 0xFF == ord( 'q'):\n",
    "        break\n",
    "cap.release\n",
    "videoWriter.release ()\n",
    "cv2. destroyAllWindows ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing if the video captured can be detected by mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2. VideoCapture ('press.avi')\n",
    "with mp_pose. Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap. read ()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor (frame, cv2. COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # Make Detections\n",
    "        results = pose.process (image)\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image. flags.writeable= True\n",
    "        image = cv2.cvtColor (image, cv2. COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose. POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec (color=(0,255,0), thickness=2,circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec (color=(0,0,255), thickness=2,circle_radius=4)\n",
    "                                \n",
    "                                )\n",
    "        k = cv2. waitKey(1)\n",
    "        cv2. imshow( 'Raw Webcam Feed', image)\n",
    "        if cv2.waitKey(1)& 0xFF == ord('q'):\n",
    "            break\n",
    "cap. release\n",
    "cv2. destroyAllWindows ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.pose_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annotating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'. format(val), 'z{}'. format(val), 'v{}'. format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv. QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmark(results, action) :\n",
    "    print(results.pose_landmarks)\n",
    "    try:\n",
    "        keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "        keypoints.insert(0, action)\n",
    "        with open( 'data/coords.csv', mode='a' , newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main code for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2. VideoCapture ('videos/press.avi')\n",
    "with mp_pose. Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap. read ()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor (frame, cv2. COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # Make Detections\n",
    "        results = pose.process (image)\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image. flags.writeable= True\n",
    "        image = cv2.cvtColor (image, cv2. COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose. POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec (color=(0,255,0), thickness=2,circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec (color=(0,0,255), thickness=2,circle_radius=4)\n",
    "                                \n",
    "                                )\n",
    "        k = cv2. waitKey(1)\n",
    "        if k == 117:\n",
    "            export_landmark(results, 'up')\n",
    "        if k == 100:\n",
    "            export_landmark(results, 'down')\n",
    "        cv2. imshow( 'Raw Webcam Feed', image)\n",
    "        if cv2.waitKey(1)& 0xFF == ord('q'):\n",
    "            break\n",
    "cap. release\n",
    "cv2. destroyAllWindows ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traning custom model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/coords.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['class']=='up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop( 'class', axis=1) # features\n",
    "y = df['class'] # target value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier \n",
    "from sklearn. ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "'Ir' :make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "'rc' :make_pipeline (StandardScaler(), RidgeClassifier()),\n",
    "'rf' :make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "'gb' :make_pipeline (StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, Y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models ['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serialize using pickel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score # Accuracy metrics \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in fit_models. items():\n",
    "    yhat = model. predict(X_test)\n",
    "    print(algo, accuracy_score(y_test.values, yhat),\n",
    "            precision_score(y_test.values,yhat, average=\"binary\", pos_label=\"up\"), \n",
    "            recall_score(y_test.values, yhat, average=\"binary\", pos_label=\"up\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( 'deadlift.pkl', 'wb') as f:\n",
    "    pickle.dump (fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "\n",
    "mp_drawing=mp.solutions.drawing_utils\n",
    "mp_pose=mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/deadlift.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/deadlift.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/Desktop/yeshu/yesuiiii/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/deadlift.pkl'"
     ]
    }
   ],
   "source": [
    "with open('../models/deadlift.pkl', 'rb') as f:\n",
    "    model=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'landmark'\n",
      "up [0.16 0.84]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.13 0.87]\n",
      "up [0.13 0.87]\n",
      "up [0.13 0.87]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.14 0.86]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.14 0.86]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.16 0.84]\n",
      "up [0.14 0.86]\n",
      "up [0.15 0.85]\n",
      "up [0.16 0.84]\n",
      "up [0.14 0.86]\n",
      "up [0.1 0.9]\n",
      "up [0.1 0.9]\n",
      "up [0.1 0.9]\n",
      "up [0.11 0.89]\n",
      "up [0.12 0.88]\n",
      "up [0.12 0.88]\n",
      "up [0.12 0.88]\n",
      "up [0.12 0.88]\n",
      "up [0.11 0.89]\n",
      "up [0.11 0.89]\n",
      "up [0.11 0.89]\n",
      "up [0.12 0.88]\n",
      "up [0.11 0.89]\n",
      "up [0.11 0.89]\n",
      "up [0.14 0.86]\n",
      "up [0.17 0.83]\n",
      "up [0.17 0.83]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.15 0.85]\n",
      "up [0.17 0.83]\n",
      "up [0.17 0.83]\n",
      "up [0.17 0.83]\n",
      "up [0.17 0.83]\n",
      "up [0.18 0.82]\n",
      "up [0.18 0.82]\n",
      "up [0.17 0.83]\n",
      "up [0.13 0.87]\n",
      "up [0.13 0.87]\n",
      "up [0.14 0.86]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2. VideoCapture (0)\n",
    "counter=0\n",
    "current_stage=''\n",
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'. format(val), 'z{}'. format(val),'v{}'.format(val)]\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap. read ()\n",
    "# Recolor Feed\n",
    "        image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "        image. flags.writeable = False\n",
    "        \n",
    "        results = pose. process (image)\n",
    "        \n",
    "        image.flags. writeable = True\n",
    "        image = cv2.cvtColor (image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose. POSE_CONNECTIONS\n",
    "                                    , mp_drawing. DrawingSpec(color=(0,255,0), thickness=2, circle_radius=4), \n",
    "                                    mp_drawing. DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)\n",
    "                                \n",
    "        )\n",
    "        try:\n",
    "            row = np.array([[res.x, res.y, res.z, res.visibility]for res in results.pose_landmarks.landmark]).flatten().tolist()  # Show the Bounding Box around the Body\n",
    "            X = pd.DataFrame([row], columns=landmarks[1:])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            \n",
    "            if body_language_class == 'down' and body_language_prob[body_language_prob.argmax()]>=0.55: \n",
    "                current_stage = 'down'\n",
    "            elif current_stage =='down' and body_language_class =='up' and body_language_prob[body_language_prob.argmax()]>0.55:\n",
    "                current_stage=\"up\"\n",
    "                counter =counter+1\n",
    "                print(current_stage)\n",
    "\n",
    "            cv2. rectangle(image, (0,0), (250, 60), (245, 117, 16), - 1)\n",
    "# Display CLass\n",
    "            cv2. putText (image, 'CLASS',\n",
    "                    (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0], (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,cv2.LINE_AA)\n",
    "            \n",
    "            cv2. putText(image, 'PROB',(15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2. putText(image, str(round(body_language_prob[np.argmax(body_language_prob)], 2)), (10,40), cv2. FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2. LINE_AA)\n",
    " \n",
    " \n",
    "            cv2. putText (image, 'COUNT', (180,12), cv2. FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2. putText (image,str(counter), (175,40), cv2. FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,cv2.LINE_AA)\n",
    "            \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        cv2. imshow( 'Raw Webcam Feed', image)\n",
    "        if cv2.waitKey (10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap. release ( )\n",
    "cv2. destroyAllWindows ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yesuiii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
